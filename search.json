[{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Introducing bgms","text":"example demonstrates use bgms Bayesian analysis binary ordinal data special network model called Markov Random Field (MRF) model. learn MRF model, check Marsman & Haslbeck (2023), learn Bayesian analysis network models, check Huth et al. (2023). paper bgms software coming soon. ’ll examine real data PTSD symptoms 362 Chinese adults survived Wenchuan earthquake tragically lost child (McNally et al., 2015). data comes 17-question survey participants rated much symptom bothered past month scale “” “extremely.”","code":"library(bgms)"},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"example-1-em","dir":"Articles","previous_headings":"","what":"Example 1 – EM","title":"Introducing bgms","text":"initial example, ’ll demonstrate quickly estimate network using bgm.em function. method similar traditional network estimation approaches seek single optimal structure minimizing model complexity. Unlike complete Bayesian analysis networks ’ll explore later, method employs EM algorithm find optimal structure (Marsman et al., 2022). goal reduce edge weights missing connections value near zero, without shrinking edge weights existing connections.","code":""},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"usage","dir":"Articles","previous_headings":"Example 1 – EM","what":"Usage","title":"Introducing bgms","text":"","code":"bgm.em(   x,   precision = 0.975,   convergence_criterion = sqrt(.Machine$double.eps),   theta = 0.5,   hierarchical = FALSE,   indicator_alpha = 1,   indicator_beta = 1,   maximum_iterations = 1000,   threshold_alpha = 1,   threshold_beta = 1 )"},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"arguments","dir":"Articles","previous_headings":"Example 1 – EM","what":"Arguments","title":"Introducing bgms","text":"x: matrix n rows p columns, containing binary ordinal variables n independent observations p variables network. Variables recoded non-negative integers (0, 1, …, m) done already. Unobserved categories collapsed categories recoding. See reformat_data details. precision: value 0 1 representing desired precision edge selection, equal one minus desired type-1 error rate. Default 0.975. convergence_criterion: criterion pseudoposterior values’ convergence EM algorithm. Default sqrt(.Machine$double.eps). theta: prior inclusion probability. value 0.5, combined hierarchical = FALSE, specifies uniform prior network structures’ space. hierarchical: TRUE, beta prior distribution hyperparameters alpha beta imposed prior inclusion probability theta. uniform prior inclusion probability, using beta alpha = beta = 1, specifies uniform prior network structure complexity. indicator_alpha, indicator_beta: Hyperparameters beta prior distribution prior inclusion probability theta hierarchical = TRUE. Default 1. maximum_iterations: Maximum number EM iterations used. Default 1e3. warning appears procedure hasn’t converged within maximum number iterations. threshold_alpha, threshold_beta: Shape parameters Beta-prime prior thresholds. Default 1.","code":""},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"output","dir":"Articles","previous_headings":"Example 1 – EM","what":"Output","title":"Introducing bgms","text":"output list containing: interactions: matrix p rows p columns, containing pairwise association estimates -diagonal elements. gamma: matrix p rows p columns, containing expected values edge inclusion variables (local posterior probabilities edge inclusion). thresholds: matrix p rows max(m) columns, containing category thresholds node. theta (hierarchical == TRUE): numeric value representing modal estimate prior inclusion probability. summary, list includes matrices interactions, gamma, thresholds, along prior inclusion probability theta hierarchical = TRUE.","code":""},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"analysis","dir":"Articles","previous_headings":"Example 1 – EM","what":"Analysis","title":"Introducing bgms","text":"Now let’s show estimated edge weights inclusion probabilities plot.  plot , observe edge values close zero associated low inclusion probabilities, non-zero edge values probabilities close one. crucial understand estimates actual posterior inclusion probabilities. goal EM algorithm identify likely network model, achieve , pushes estimated inclusion probabilities towards extreme values (either 0 1). result, estimated probabilities don’t represent probability observed data come network edge question (posterior inclusion probability). Instead, indicate probability edge included likely model. using EM edge selection, median probability model network model includes edges probability 0.5 higher. approach selects likely network structure EM algorithm pushes inclusion probabilities towards extreme values. However, lead local optimum, implying , optimal network structures may exist. Therefore, refer local median probability model. code extract plot local median probability network:  method offers quick computationally efficient way start exploring data. estimates single network structure seems best fit data . However, doesn’t show uncertain estimate whether plausible structures also fit data. contrast, Bayesian model averaging (BMA) considers possible network structures probabilities. BMA combines information multiple network structures create robust accurate representation variable relationships. weighting network’s contribution based posterior probability, BMA addresses model uncertainty, resulting nuanced stable outcomes compared median probability model using EM variable selection.","code":"fit <- bgm.em(x = Wenchuan) par(mar = c(6, 5, 1, 1)) plot(x = fit$interactions[lower.tri(fit$interactions)],      y = fit$gamma[lower.tri(fit$gamma)], ylim = c(0, 1),      xlab = \"\", ylab = \"\", axes = FALSE, pch = 21, bg = \"#bfbfbf\", cex = 1.3) abline(h = 0, lty = 2, col = \"#bfbfbf\") abline(h = 1, lty = 2, col = \"#bfbfbf\") abline(h = .5, lty = 2, col = \"#bfbfbf\") mtext(\"Posterior mode edge weight\", side = 1, line = 3, cex = 1.7) mtext(\"(Local) posterior inclusion probability\", side = 2, line = 3, cex = 1.7) axis(1)  axis(2, las = 1) library(qgraph) #For plotting the estimated network    posterior.inclusion <- fit$gamma[lower.tri(fit$gamma)] tmp <- fit$interactions[lower.tri(fit$interactions)] tmp[posterior.inclusion < 0.5] = 0    median.prob.model <- matrix(0, nrow = ncol(Wenchuan), ncol = ncol(Wenchuan)) median.prob.model[lower.tri(median.prob.model)] <- tmp median.prob.model <- median.prob.model + t(median.prob.model)    rownames(median.prob.model) <- colnames(Wenchuan) colnames(median.prob.model) <- colnames(Wenchuan)    qgraph(median.prob.model,        theme = \"TeamFortress\",        maximum = .5,       fade = FALSE,       color = c(\"#f0ae0e\"), vsize = 10, repulsion = .9,        label.cex = 1.1, label.scale = \"FALSE\",        labels = colnames(Wenchuan))"},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"example-2-bma","dir":"Articles","previous_headings":"","what":"Example 2 – BMA","title":"Introducing bgms","text":"comprehensive Bayesian analysis data considers network structure corresponding parameters. numerous structures underlie network, employ simulation-based methods investigate posterior distribution network structures parameters (Marsman & Haslbeck, 2023). bgm function performs task, iteratively simulating values posterior distribution network structures parameters. Though method takes time compared previously discussed EM approach, offers deeper insights.","code":""},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"usage-1","dir":"Articles","previous_headings":"Example 2 – BMA","what":"Usage","title":"Introducing bgms","text":"","code":"bgm(   x,   iter = 10000,   burnin = 1000,   interaction_prior = c(\"UnitInfo\", \"Cauchy\"),   cauchy_scale = 2.5,   threshold_alpha = 1,   threshold_beta = 1,   save = FALSE,   display_progress = TRUE )"},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"arguments-1","dir":"Articles","previous_headings":"Example 2 – BMA","what":"Arguments","title":"Introducing bgms","text":"x: matrix n rows p columns, containing binary ordinal variables n independent observations p variables network. Variables recoded non-negative integers (0, 1, …, m) done already. Unobserved categories collapsed categories recoding. See reformat_data details. iter: number iterations Gibbs sampler. Defaults 1e4. better estimates, recommended run procedure least 1e5 iterations. burnin: number burnin iterations. output Gibbs sampler stored burnin iterations. interaction_prior: prior distribution interaction effects. Currently, two prior densities implemented: Unit Information prior (interaction_prior = \"UnitInfo\") Cauchy prior (interaction_prior = \"Cauchy\"). Defaults \"UnitInfo\". cauchy_scale: scale Cauchy prior interactions. Defaults 2.5. threshold_alpha, threshold_beta: shape parameters Beta-prime prior thresholds. Defaults 1. save: function collect return samples Gibbs sampler (save = TRUE)? return (model-averaged) posterior means (save = FALSE)? Defaults FALSE. display_progress: function show progress bar (display_progress = TRUE)? (display_progress = FALSE)? Defaults TRUE.","code":""},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"output-1","dir":"Articles","previous_headings":"Example 2 – BMA","what":"Output","title":"Introducing bgms","text":"save = FALSE (default), result list containing following matrices: gamma: matrix p rows p columns, containing posterior inclusion probabilities individual edges. interactions: matrix p rows p columns, containing model-averaged posterior means pairwise associations. thresholds: matrix p rows max(m) columns, containing model-averaged category thresholds. save = TRUE, result list containing: samples.gamma: matrix iter rows p * (p - 1) / 2 columns, containing edge inclusion indicators every iteration Gibbs sampler. samples.interactions: matrix iter rows p * (p - 1) / 2 columns, containing parameter states every iteration Gibbs sampler pairwise associations. samples.thresholds: matrix iter rows sum(m) columns, containing parameter states every iteration Gibbs sampler category thresholds. Column averages matrices provide model-averaged posterior means.","code":""},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"analysis-1","dir":"Articles","previous_headings":"Example 2 – BMA","what":"Analysis","title":"Introducing bgms","text":"save time, ran algorithm using default number iterations, 10,000. However, may enough fully explore posterior distribution network structures parameters. obtain reliable accurate estimates, recommend increasing number iterations 100,000 . Let’s reproduce plot previous example.  plot looks similar Example 1 edge values near zero low inclusion probabilities, edge values far zero high inclusion probabilities. However, differs two ways: relationship inclusion probability edge weights takes different shape edge weights close zero. variety inclusion probabilities Example 2 Example 1. differences happen edge weights handled. bgm.em bgm use diffuse prior density edge weights included edges, handle absent edges differently. bgm.em uses continuous density tightly wrapped around zero (small variance scale value). causes edge weights absent edges close zero, exactly zero. hand, bgm sets edge weights exactly zero edge excluded. accounts difference curved relationship inclusion probability estimated edge weight around zero Example 1 V-shaped relationship Example 2. greater variety inclusion probabilities Example 2 results bgm function using EM algorithm find likely model, push inclusion probabilities towards extremes. Instead, employs simulation method averages plausible network structures estimate posterior inclusion probability, represents probability network containing edge question generated observed data.","code":"fit <-  bgm(x = Wenchuan) par(mar = c(6, 5, 1, 1)) plot(x = fit$interactions[lower.tri(fit$interactions)],       y = fit$gamma[lower.tri(fit$gamma)], ylim = c(0, 1),       xlab = \"\", ylab = \"\", axes = FALSE, pch = 21, bg = \"gray\", cex = 1.3) abline(h = 0, lty = 2, col = \"gray\") abline(h = 1, lty = 2, col = \"gray\") abline(h = .5, lty = 2, col = \"gray\") mtext(\"Posterior mean edge weight\", side = 1, line = 3, cex = 1.7) mtext(\"Posterior inclusion probability\", side = 2, line = 3, cex = 1.7) axis(1) axis(2, las = 1)"},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"median-probability-network","dir":"Articles","previous_headings":"Example 2 – BMA > Analysis","what":"Median probability network","title":"Introducing bgms","text":"Using posterior inclusion probabilities, can also identify median probability network. network, include edges posterior inclusion probability greater 0.5. can reuse code earlier create median probability model.  ’s worth noting model connections local median probability model estimated EM. Although structure estimated EM plausible, network structures also deemed plausible given data. result, connections included median probability model.","code":"library(qgraph) #For plotting the estimated network    posterior.inclusion <- fit$gamma[lower.tri(fit$gamma)] tmp <- fit$interactions[lower.tri(fit$interactions)] tmp[posterior.inclusion < 0.5] = 0    median.prob.model <- matrix(0, nrow = ncol(Wenchuan), ncol = ncol(Wenchuan)) median.prob.model[lower.tri(median.prob.model)] <- tmp median.prob.model <- median.prob.model + t(median.prob.model)    rownames(median.prob.model) <- colnames(Wenchuan) colnames(median.prob.model) <- colnames(Wenchuan)    qgraph(median.prob.model,         theme = \"TeamFortress\",         maximum = .5,        fade = FALSE,        color = c(\"#f0ae0e\"), vsize = 10, repulsion = .9,         label.cex = 1.1, label.scale = \"FALSE\",         labels = colnames(Wenchuan))"},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"inclusion-bayes-factors","dir":"Articles","previous_headings":"Example 2 – BMA > Analysis","what":"Inclusion Bayes factors","title":"Introducing bgms","text":"One benefits using fully Bayesian approach allows us calculate inclusion Bayes factor Huth et al. (2023). inclusion Bayes factor represents relative evidence including excluding connection pair nodes network. inclusion Bayes factor 10 suggests observed data ten times likely come network includes relationship. Conversely, inclusion Bayes factor 1/10 implies observed data ten times likely come network excludes relationship. ’s important note inclusion Bayes factors can also reveal limited support either hypothesis. current version bgms, assumed prior inclusion probabilities equal 0.5. calculate inclusion Bayes factors, can simply convert estimated posterior inclusion probabilities. easier visualization, common use natural logarithm Bayes factor plotting. Lets plot relation estimated edge weights inclusion Bayes factor.  example, use cut-value 10 inclusion Bayes factors. Values greater 10 suggest evidence edge inclusion, values less 1/10 indicate evidence edge exclusion, values 1/10 10 considered represent weak evidence.","code":"# Calculate the inclusion BFs prior.odds = 1 posterior.inclusion = fit$gamma[lower.tri(fit$gamma)] posterior.odds = posterior.inclusion / (1 - posterior.inclusion) log.bayesfactor = log(posterior.odds / prior.odds) #The next line is used to truncate the extreme values of the Bayes factor in the plot log.bayesfactor[log.bayesfactor > 5] = 5 par(mar = c(5, 5, 1, 1) + 0.1) plot(fit$interactions[lower.tri(fit$interactions)], log.bayesfactor, pch = 21, bg = \"#bfbfbf\",      cex = 1.3, axes = FALSE, xlab = \"\", ylab = \"\", ylim = c(-5, 5.5),     xlim = c(-0.5, 1.5)) axis(1) axis(2, las = 1) abline(h = log(1/10), lwd = 2, col = \"#bfbfbf\") abline(h = log(10), lwd = 2, col = \"#bfbfbf\")  text(x = 1, y = log(1 / 10), labels = \"Evidence for exclusion\", pos = 1,     cex = 1.7) text(x = 1, y = log(10), labels = \"Evidence for inclusion\", pos = 3, cex = 1.7) text(x = 1, y = 0, labels = \"Weak evidence\", cex = 1.7) mtext(\"Log-inclusion Bayes factor\", side = 2, line = 3, cex = 1.5, las = 0) mtext(\"Posterior mean edge weights \", side = 1, line = 3.7, cex = 1.5, las = 0)"},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"analysis-with-raw-output","dir":"Articles","previous_headings":"Example 2 – BMA","what":"Analysis with raw output","title":"Introducing bgms","text":"purposes, default output bgm sufficient, providing us posterior means edge indicators parameters. However, cases, may want use raw samples joint posterior distribution. estimate posterior distribution specific parameter, assess many network structures fit given data, create Bayes factors hypotheses involving multiple edges. can obtain raw samples setting save = TRUE.","code":"fit <-  bgm(x = Wenchuan, save = TRUE)"},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"posterior-density-of-edge-weight","dir":"Articles","previous_headings":"Example 2 – BMA > Analysis with raw output","what":"Posterior density of edge weight","title":"Introducing bgms","text":"can employ following code use posterior samples plotting posterior density single edge:  posterior distribution edge weight averaged across structures, can lead greater dispersion compared estimating specific model. takes account uncertainty network structures parameter estimates associated structures. Note estimate smooth. used 10,000 samples estimate posterior distribution.","code":"den = density(fit$interactions[,1], bw = \"SJ\") i = which.min(abs(den$x - mean(fit$interactions[,1])))[1] x = den$x[i] f = den$y[i] par(cex.main = 1.5, mar = c(5, 6, 1, 1) + 0.1, mgp = c(3.5, 1, 0), cex.lab = 1.5, font.lab = 2, cex.axis = 1.3, bty = \"n\", las = 1) plot(den, axes = FALSE, xlab=\"\", ylab=\"\", main = \"\", frame.plot = FALSE) axis(1) axis(2) par(las = 0) mtext(text = \"Edge weight\", side = 1, line = 2.5, cex = 1.5) mtext(text = \"Posterior density\", side = 2, line = 2.5, cex = 1.5) # Add a point to indicate the posterior mean points(x, f, pch = 21, bg = \"grey\", cex = 1.7)"},{"path":"https://maartenMarsman.github.io/bgms/articles/introduction.html","id":"the-posterior-distribution-of-structures","dir":"Articles","previous_headings":"Example 2 – BMA","what":"The posterior distribution of structures","title":"Introducing bgms","text":"can also use raw samples count number unique structures bgm encountered 10,000 iterations. clearly many different network structures fit data. Let’s estimate posterior probabilities. plausible model accounts less 1 percent posterior probability. conclusion, significant uncertainty network structure generated data. analysis Marsman & Haslbeck (2023), demonstrated even uncertainty network structure generated data, inclusion Bayes factors highly robust. can help identify substructures network strong confidence. However, perform analyses, need run bgm many iterations. analysis, Marsman & Haslbeck (2023) used 1,000,000 iterations. details, interested readers can refer analysis script .","code":"G = 2 * fit$gamma - 1 S = unique(G) nrow(S) #> [1] 9940 Ps = vector(length = nrow(S)) for(r in 1:nrow(S)) {   s = S[r, ]   tmp = G %*% s   Ps[r] = sum(tmp == ncol(G)) } Ps = Ps / nrow(G) * 100 max(Ps) #> [1] 0.03"},{"path":[]},{"path":"https://maartenMarsman.github.io/bgms/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Maarten Marsman. Author, maintainer. Nikola Sekulovski. Contributor. Don van den Bergh. Contributor.","code":""},{"path":"https://maartenMarsman.github.io/bgms/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Marsman, M., & Haslbeck, J. M. B. (2023, March 3). Bayesian Analysis Ordinal Markov Random Field. https://doi.org/10.31234/osf.io/ukwrf","code":"@Article{,   title = {Bayesian Analysis of the Ordinal Markov Random Field},   author = {{Marsman} and {M.} and {Haslbeck} and J. M. B.},   journal = {PsyArXiv},   year = {2023},   url = {https://psyarxiv.com/ukwrf}, }"},{"path":"https://maartenMarsman.github.io/bgms/index.html","id":"bgms-bayesian-analysis-of-graphical-models","dir":"","previous_headings":"","what":"Bayesian Variable Selection for Networks of Binary and/or Ordinal Variables","title":"Bayesian Variable Selection for Networks of Binary and/or Ordinal Variables","text":"R package bgms provides tools Bayesian analysis graphical models describing networks variables. package uses Bayesian variable selection methods model underlying network structure. methods organized around two general approaches Bayesian variable selection: (1) EM variable selection (2) Gibbs variable selection. key distinction former uses continuous spike slab prior distribution pairwise interactions (Marsman et al. 2022) allows us use EM variable selection (Ročková George 2014). Gibbs variable selection approach (George McCulloch 1993), hand, stipulates discrete spike slab prior pairwise interactions, allows us set interactions exact zeroes. account discontinuity zero, embed Metropolis approach mixtures mutually singular distributions (Gottardo Raftery 2008) Gibbs sampler. goal provide tools Markov Random Field (MRF) models wide range variable types bgms package, currently provides analyzing networks binary /ordinal variables (Marsman Haslbeck 2023).","code":""},{"path":"https://maartenMarsman.github.io/bgms/index.html","id":"why-use-markov-random-fields","dir":"","previous_headings":"","what":"Why use Markov Random Fields?","title":"Bayesian Variable Selection for Networks of Binary and/or Ordinal Variables","text":"Multivariate analysis using graphical models received much attention recent psychological psychometric literature (Robinaugh et al. 2020; Marsman Rhemtulla 2022; Steinley 2021; Contreras et al. 2019). graphical models Markov Random Field (MRF) models, whose graph structure reflects conditional associations variables (Kindermann Snell 1980). models, missing edge two variables network implies variables independent, given remaining variables (Lauritzen 2004). words, remaining variables network fully account potential association unconnected variables.","code":""},{"path":"https://maartenMarsman.github.io/bgms/index.html","id":"why-use-a-bayesian-approach-to-analyze-the-mrf","dir":"","previous_headings":"","what":"Why use a Bayesian approach to analyze the MRF?","title":"Bayesian Variable Selection for Networks of Binary and/or Ordinal Variables","text":"Testing structure MRF requires us determine plausibility opposing hypotheses conditional dependence conditional independence. example, plausible network structures include edge variables 3 9 compared network structures exclude edge? Frequentist approaches limited respect, can reject conditional independence hypothesis, support (Wagenmakers et al. 2018; Wagenmakers 2007). creates problem , edge excluded, know whether edge absent population, lack power reject null hypothesis independence. avoid problem, use Bayesian approach using Bayes factors (Kass Raftery 1995). inclusion Bayes factor (Huth et al. 2023) allows us quantify much data support conditional dependence —evidence edge presence— conditional independence —evidence edge absence. also allows us conclude limited support either hypothesis (Dienes 2014) —absence evidence.","code":""},{"path":"https://maartenMarsman.github.io/bgms/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Variable Selection for Networks of Binary and/or Ordinal Variables","text":"can install latest version CRAN using: current developmental version can installed ","code":"install.packages(\"bgms\") if (!requireNamespace(\"remotes\")) {    install.packages(\"remotes\")    }    remotes::install_github(\"MaartenMarsman/bgms\")"},{"path":[]},{"path":"https://maartenMarsman.github.io/bgms/reference/Wenchuan.html","id":null,"dir":"Reference","previous_headings":"","what":"Post-traumatic stress disorder symptoms of Wenchuan earthquake survivors — Wenchuan","title":"Post-traumatic stress disorder symptoms of Wenchuan earthquake survivors — Wenchuan","text":"data set containing items measuring symptoms posttraumatic stress  disorder (PTSD) (McNally et al. 2015) . Participants 362  Chinese adults survived Wenchuan earthquake lost least one  child disaster. PTSD symptoms reported using civilian version  Posttraumatic Checklist, consists 17 items, assessing  one DSM-IV symptoms PTSD. Participants rated item  five-point scale ranging ``'' ``extremely'' indicate  much symptom bothered past month.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/Wenchuan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Post-traumatic stress disorder symptoms of Wenchuan earthquake survivors — Wenchuan","text":"","code":"data(\"Wenchuan\")"},{"path":"https://maartenMarsman.github.io/bgms/reference/Wenchuan.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Post-traumatic stress disorder symptoms of Wenchuan earthquake survivors — Wenchuan","text":"matrix 362 rows 17 columns: intrusion Repeated, disturbing memories, thoughts, images    stressful experience past? dreams Repeated, disturbing dreams stressful experience    past? flash Suddenly acting feeling stressful experience    happening (reliving )? upset Feeling upset something reminded stressful    experience past? physior physical reactions (e.g., heart pounding, trouble    breathing, sweating) something reminded stressful experience    past? avoidth Avoiding thinking talking stressful    experience past avoiding feelings related ? avoidact Avoiding activities situations reminded    stressful experience past? amnesia Trouble remembering important parts stressful    experience past? lossint Loss interest activities used enjoy? distant Feeling distant cut people? numb Feeling emotionally numb unable loving    feelings close ? future Feeling future somehow cut short? sleep Trouble falling staying asleep? anger Feeling irritable angry outbursts? concen difficulty concentrating? hyper \"super-alert\" watchful guard? startle Feeling jumpy easily startled?","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/Wenchuan.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Post-traumatic stress disorder symptoms of Wenchuan earthquake survivors — Wenchuan","text":"http://psychosystems.org/wp-content/uploads/2014/10/Wenchuan.csv","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/Wenchuan.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Post-traumatic stress disorder symptoms of Wenchuan earthquake survivors — Wenchuan","text":"McNally RJ, Robinaugh DJ, Wu GWY, Wang L, Deserno MK, Borsboom D (2015). “Mental disorders causal systems: network approach posttraumatic stress disorder.” Clinical Psychological Science, 5(6), 836--849. doi:10.1177/2167702614553230 .","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.em.html","id":null,"dir":"Reference","previous_headings":"","what":"EM variable selection for a Markov Random Field model for ordinal variables. — bgm.em","title":"EM variable selection for a Markov Random Field model for ordinal variables. — bgm.em","text":"function bgm.em selects promising edges ordinal MRF using joint pseudolikelihood continuous spike slab prior distribution stipulated MRF's interaction association parameters.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.em.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EM variable selection for a Markov Random Field model for ordinal variables. — bgm.em","text":"","code":"bgm.em(   x,   precision = 0.975,   convergence_criterion = sqrt(.Machine$double.eps),   theta = 0.5,   hierarchical = FALSE,   indicator_alpha = 1,   indicator_beta = 1,   maximum_iterations = 1000,   threshold_alpha = 1,   threshold_beta = 1 )"},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.em.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EM variable selection for a Markov Random Field model for ordinal variables. — bgm.em","text":"x matrix n rows p columns, containing binary ordinal variables n independent observations p variables network. Variables recoded non-negative integers (0, 1, ..., m) done already. Unobserved categories collapsed categories recoding. See reformat_data details. precision value 0 1 representing desired precision edge selection, equal one minus desired type-1 error rate. Default 0.975. convergence_criterion criterion pseudoposterior values' convergence EM algorithm. Default sqrt(.Machine$double.eps). theta prior inclusion probability. value 0.5, combined hierarchical = FALSE, specifies uniform prior network structures' space. hierarchical TRUE, beta prior distribution hyperparameters indicator_alpha, indicator_beta imposed prior inclusion probability theta. uniform prior inclusion probability, using beta indicator_alpha = indicator_beta = 1, specifies uniform prior network structure complexity. indicator_alpha, indicator_beta Hyperparameters beta prior distribution prior inclusion probability theta hierarchical = TRUE. Default 1. maximum_iterations Maximum number EM iterations used. Default 1e3. warning appears procedure converged within maximum number iterations. threshold_alpha, threshold_beta Shape parameters Beta-prime prior thresholds. Default 1.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.em.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EM variable selection for a Markov Random Field model for ordinal variables. — bgm.em","text":"list containing: interactions: matrix p rows p columns, containing pairwise association estimates -diagonal elements. gamma: matrix p rows p columns, containing expected values edge inclusion variables (local posterior probabilities edge inclusion). thresholds: matrix p rows max(m) columns, containing category thresholds node. theta (hierarchical == TRUE): numeric value representing modal estimate prior inclusion probability.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.em.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EM variable selection for a Markov Random Field model for ordinal variables. — bgm.em","text":"","code":"# \\donttest{  #Store user par() settings  op <- par(no.readonly = TRUE)   ##Analyse the Wenchuan dataset  fit = bgm.em(x = Wenchuan) #> Warning: There were 18 rows with missing observations in the input matrix x. #> Since bgms cannot handle missing responses, these rows were  #> excluded from the analysis.    #------------------------------------------------------------------------------|  # INCLUSION - EDGE WEIGHT PLOT  #------------------------------------------------------------------------------|   par(mar = c(6, 5, 1, 1))  plot(x = fit$interactions[lower.tri(fit$interactions)],       y = fit$gamma[lower.tri(fit$gamma)], ylim = c(0, 1),       xlab = \"\", ylab = \"\", axes = FALSE, pch = 21, bg = \"#bfbfbf\", cex = 1.3)  abline(h = 0, lty = 2, col = \"#bfbfbf\")  abline(h = 1, lty = 2, col = \"#bfbfbf\")  abline(h = .5, lty = 2, col = \"#bfbfbf\")  mtext(\"Posterior Inclusion Probability\", side = 1, line = 3, cex = 1.7)  mtext(\"Posterior Mode Edge Weight\", side = 2, line = 3, cex = 1.7)  axis(1)  axis(2, las = 1)     #------------------------------------------------------------------------------|  # THE LOCAL MEDIAN PROBABILITY NETWORK  #------------------------------------------------------------------------------|   library(qgraph) #For plotting the estimated network   posterior.inclusion = fit$gamma[lower.tri(fit$gamma)]  tmp = fit$interactions[lower.tri(fit$interactions)]  tmp[posterior.inclusion < 0.5] = 0   median.prob.model = matrix(0, nrow = ncol(Wenchuan), ncol = ncol(Wenchuan))  median.prob.model[lower.tri(median.prob.model)] = tmp  median.prob.model = median.prob.model + t(median.prob.model)   rownames(median.prob.model) = colnames(Wenchuan)  colnames(median.prob.model) = colnames(Wenchuan)   qgraph(median.prob.model,         theme = \"TeamFortress\",         maximum = .5,         fade = FALSE,         color = c(\"#f0ae0e\"), vsize = 10, repulsion = .9,         label.cex = 1.1, label.scale = \"FALSE\",         labels = colnames(Wenchuan))    #Restore user par() settings  par(op) # }"},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian structure learning in Markov Random Fields of mixed binary and\nordinal variables using MCMC. — bgm","title":"Bayesian structure learning in Markov Random Fields of mixed binary and\nordinal variables using MCMC. — bgm","text":"function bgm explores joint pseudoposterior distribution structures parameters Markov Random Field mixed binary ordinal variables.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian structure learning in Markov Random Fields of mixed binary and\nordinal variables using MCMC. — bgm","text":"","code":"bgm(   x,   iter = 10000,   burnin = 1000,   interaction_prior = c(\"UnitInfo\", \"Cauchy\"),   cauchy_scale = 2.5,   threshold_alpha = 1,   threshold_beta = 1,   save = FALSE,   display_progress = TRUE )"},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian structure learning in Markov Random Fields of mixed binary and\nordinal variables using MCMC. — bgm","text":"x matrix n rows p columns, containing binary ordinal variables n independent observations p variables network. Variables recoded non-negative integers (0, 1, ..., m) done already. Unobserved categories collapsed categories recoding. See reformat_data details. iter number iterations Gibbs sampler. Defaults 1e4. better estimates, recommended run procedure least 1e5 iterations. burnin number burnin iterations. output Gibbs sampler stored burnin iterations. interaction_prior prior distribution interaction effects. Currently, two prior densities implemented: Unit Information prior (interaction_prior = \"UnitInfo\") Cauchy prior (interaction_prior = \"Cauchy\"). Defaults \"UnitInfo\". cauchy_scale scale Cauchy prior interactions. Defaults 2.5. threshold_alpha, threshold_beta shape parameters Beta-prime prior thresholds. Defaults 1. save function collect return samples Gibbs sampler (save = TRUE)? return (model-averaged) posterior means (save = FALSE)? Defaults FALSE. display_progress function show progress bar (display_progress = TRUE)? (display_progress = FALSE)? Defaults TRUE.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian structure learning in Markov Random Fields of mixed binary and\nordinal variables using MCMC. — bgm","text":"save = FALSE (default), result list containing following matrices: gamma: matrix p rows p columns, containing posterior inclusion probabilities individual edges. interactions: matrix p rows p columns, containing model-averaged posterior means pairwise associations. thresholds: matrix p rows max(m) columns, containing model-averaged category thresholds. save = TRUE, result list containing: samples.gamma: matrix iter rows p * (p - 1) / 2 columns, containing edge inclusion indicators every iteration Gibbs sampler. samples.interactions: matrix iter rows p * (p - 1) / 2 columns, containing parameter states every iteration Gibbs sampler pairwise associations. samples.thresholds: matrix iter rows sum(m) columns, containing parameter states every iteration Gibbs sampler category thresholds. Column averages matrices provide model-averaged posterior means.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian structure learning in Markov Random Fields of mixed binary and\nordinal variables using MCMC. — bgm","text":"discrete spike slab prior distribution stipulated pairwise interactions. formulating mixture mutually singular distributions, function can use combination Metropolis-Hastings Gibbs sampling create Markov chain joint posterior distribution invariant. Current options slab distribution unit-information prior Cauchy optional scaling parameter. Beta-prime distribution used exponent category parameters. uniform prior used edge inclusion variables (.e., prior probability edge included 0.5).","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/bgm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian structure learning in Markov Random Fields of mixed binary and\nordinal variables using MCMC. — bgm","text":"","code":"# \\donttest{  #Store user par() settings  op <- par(no.readonly = TRUE)   ##Analyse the Wenchuan dataset   # Here, we use 1e4 iterations, for an actual analysis please use at least  # 1e5 iterations.  fit = bgm(x = Wenchuan) #> Warning: There were 18 rows with missing observations in the input matrix x. #> Since bgms cannot handle missing responses, these rows were  #> excluded from the analysis.    #------------------------------------------------------------------------------|  # INCLUSION - EDGE WEIGHT PLOT  #------------------------------------------------------------------------------|   par(mar = c(6, 5, 1, 1))  plot(x = fit$interactions[lower.tri(fit$interactions)],       y = fit$gamma[lower.tri(fit$gamma)], ylim = c(0, 1),       xlab = \"\", ylab = \"\", axes = FALSE, pch = 21, bg = \"gray\", cex = 1.3)  abline(h = 0, lty = 2, col = \"gray\")  abline(h = 1, lty = 2, col = \"gray\")  abline(h = .5, lty = 2, col = \"gray\")  mtext(\"Posterior Mode Edge Weight\", side = 1, line = 3, cex = 1.7)  mtext(\"Posterior Inclusion Probability\", side = 2, line = 3, cex = 1.7)  axis(1)  axis(2, las = 1)     #------------------------------------------------------------------------------|  # EVIDENCE - EDGE WEIGHT PLOT  #------------------------------------------------------------------------------|   #The bgms package currently assumes that the prior odds are 1:  prior.odds = 1  posterior.inclusion = fit$gamma[lower.tri(fit$gamma)]  posterior.odds = posterior.inclusion / (1 - posterior.inclusion)  log.bayesfactor = log(posterior.odds / prior.odds)  log.bayesfactor[log.bayesfactor > 5] = 5   par(mar = c(5, 5, 1, 1) + 0.1)  plot(fit$interactions[lower.tri(fit$interactions)], log.bayesfactor, pch = 21, bg = \"#bfbfbf\",       cex = 1.3, axes = FALSE, xlab = \"\", ylab = \"\", ylim = c(-5, 5.5),       xlim = c(-0.5, 1.5))  axis(1)  axis(2, las = 1)  abline(h = log(1/10), lwd = 2, col = \"#bfbfbf\")  abline(h = log(10), lwd = 2, col = \"#bfbfbf\")   text(x = 1, y = log(1 / 10), labels = \"Evidence for Exclusion\", pos = 1,       cex = 1.7)  text(x = 1, y = log(10), labels = \"Evidence for Inclusion\", pos = 3, cex = 1.7)  text(x = 1, y = 0, labels = \"Absence of Evidence\", cex = 1.7)  mtext(\"Log-Inclusion Bayes Factor\", side = 2, line = 3, cex = 1.5, las = 0)  mtext(\"Posterior Mean Interactions \", side = 1, line = 3.7, cex = 1.5, las = 0)    #------------------------------------------------------------------------------|  # THE LOCAL MEDIAN PROBABILITY NETWORK  #------------------------------------------------------------------------------|   tmp = fit$interactions[lower.tri(fit$interactions)]  tmp[posterior.inclusion < 0.5] = 0   median.prob.model = matrix(0, nrow = ncol(Wenchuan), ncol = ncol(Wenchuan))  median.prob.model[lower.tri(median.prob.model)] = tmp  median.prob.model = median.prob.model + t(median.prob.model)   rownames(median.prob.model) = colnames(Wenchuan)  colnames(median.prob.model) = colnames(Wenchuan)   library(qgraph)   qgraph(median.prob.model,         theme = \"TeamFortress\",         maximum = .5,         fade = FALSE,         color = c(\"#f0ae0e\"), vsize = 10, repulsion = .9,         label.cex = 1.1, label.scale = \"FALSE\",         labels = colnames(Wenchuan))    #Restore user par() settings  par(op) # }"},{"path":"https://maartenMarsman.github.io/bgms/reference/bgms-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bgms: Bayesian Analysis of Graphical Models — bgms-package","title":"bgms: Bayesian Analysis of Graphical Models — bgms-package","text":"R package bgms provides tools Bayesian analysis graphical models describing networks variables. package uses Bayesian variable selection methods model underlying network structure. package organized around two Bayesian variable selection approaches: (1) EM variable selection, (2) Gibbs variable selection. key distinction former uses continuous spike slab prior distribution pairwise interactions (Marsman et al. 2022)  allows us use EM variable selection (Ročková George 2014) . Gibbs variable selection approach (George McCulloch 1993) , hand, stipulates discrete spike slab prior pairwise interactions, allows us set interactions exact zeroes. account discontinuity zero, embed Metropolis approach mixtures mutually singular distributions (Gottardo Raftery 2008)  Gibbs sampler. goal provide tools Markov Random Field (MRF) models wide range variable types bgms package, currently provides tools analyzing networks binary /ordinal variables (Marsman Haslbeck 2023) . MRFs special class graphical models whose graph structure reflects conditional associations variables. Bayes factor tests inclusion exclusion edge MRF thus compare conditional dependence conditional independence hypotheses corresponding network variables (Huth et al. 2023) . bgms package offers several tools analyzing structure MRF: Simulate response data MRF using Gibbs sampler. Simulate mrfSampler. Estimate structure MRF using EM variable selection. Network estimation bgm.em. Estimate posterior distribution MRF's network structure  using Gibbs variable selection. Structure learning bgm. Additional Features: Optimizing joint pseudolikelihood mple. Optimizing joint pseudoposterior mppe.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/bgms-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"bgms: Bayesian Analysis of Graphical Models — bgms-package","text":"George EI, McCulloch RE (1993). “Variable selection via Gibbs sampling.” Journal American Statistical Association, 88(423), 881-889. doi:10.1080/01621459.1993.10476353 . Gottardo R, Raftery AE (2008). “Markov Chain Monte Carlo Mixtures Mutually Singular Distributions.” Journal Computational Graphical Statistics, 17(4), 949--975. doi:10.1198/106186008X386102 . Huth K, de Ron J, Goudriaan AE, Luigjes K, Mohammadi R, van Holst RJ, Wagenmakers E, Marsman M (2023). “Bayesian analysis cross-sectional networks: tutorial R JASP.” PsyArXiv. doi:10.31234/osf.io/ub5tc . Marsman M, Haslbeck JMB (2023). “Bayesian analysis ordinal Markov Random Field.” PsyArXiv. doi:10.31234/osf.io/ukwrf . Marsman M, Huth KBS, Waldorp LJ, Ntzoufras (2022). “Objective Bayesian edge screening structure selection Ising networks.” Psychometrika, 87(1), 47--82. doi:10.1007/s11336-022-09848-8 . Ročková V, George EI (2014). “EMVS: EM approach Bayesian variable selection.” Journal American Statistical Association, 109(506), 828--846. doi:10.1080/01621459.2013.869223 .","code":""},{"path":[]},{"path":"https://maartenMarsman.github.io/bgms/reference/bgms-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bgms: Bayesian Analysis of Graphical Models — bgms-package","text":"Maintainer: Maarten Marsman m.marsman@uva.nl (ORCID) contributors: Nikola Sekulovski (ORCID) [contributor] Don van den Bergh (ORCID) [contributor]","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/mple.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum Pseudolikelihood Estimation for an Ordinal Markov Random Field Model — mple","title":"Maximum Pseudolikelihood Estimation for an Ordinal Markov Random Field Model — mple","text":"function mple estimates parameters ordinal MRF optimizing joint pseudolikelihood Newton-Raphson method.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/mple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum Pseudolikelihood Estimation for an Ordinal Markov Random Field Model — mple","text":"","code":"mple(   x,   convergence_criterion = sqrt(.Machine$double.eps),   maximum_iterations = 1000,   thresholds,   interactions )"},{"path":"https://maartenMarsman.github.io/bgms/reference/mple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum Pseudolikelihood Estimation for an Ordinal Markov Random Field Model — mple","text":"x matrix n rows p columns, containing binary ordinal variables n independent observations p variables network. Variables recoded non-negative integers (0, 1, ..., m) done already. Unobserved categories collapsed categories recoding. See reformat_data details. convergence_criterion convergence criterion pseudoposterior values EM algorithm. Defaults sqrt(.Machine$double.eps). maximum_iterations maximum number EM iterations used. Defaults 1e3. warning issued procedure converged maximum_iterations iterations. thresholds matrix p rows max(m) columns, containing category thresholds node. Used starting values Newton-Raphson procedure. Optional. interactions matrix p rows p columns, containing pairwise association estimates -diagonal elements. Used starting values Newton-Raphson procedure. Optional.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/mple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum Pseudolikelihood Estimation for an Ordinal Markov Random Field Model — mple","text":"list containing: interactions: matrix p rows p columns, containing maximum pseudolikelihood estimates pairwise associations -diagonal elements. thresholds: matrix p rows max(m) columns, containing maximum pseudolikelihood estimates category thresholds node.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/mppe.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimize Pseudoposterior for an Ordinal Markov Random Field Model — mppe","title":"Optimize Pseudoposterior for an Ordinal Markov Random Field Model — mppe","text":"function mppe estimates parameters ordinal MRF optimizing pseudoposterior Newton-Raphson method.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/mppe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimize Pseudoposterior for an Ordinal Markov Random Field Model — mppe","text":"","code":"mppe(   x,   interaction_prior = \"Cauchy\",   cauchy_scale = 2.5,   threshold_alpha = 1,   threshold_beta = 1,   convergence_criterion = sqrt(.Machine$double.eps),   maximum_iterations = 1000,   thresholds,   interactions )"},{"path":"https://maartenMarsman.github.io/bgms/reference/mppe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimize Pseudoposterior for an Ordinal Markov Random Field Model — mppe","text":"x matrix n rows p columns, containing binary ordinal variables n independent observations p variables network. Variables recoded non-negative integers (0, 1, ..., m) done already. Unobserved categories collapsed categories recoding. See reformat_data details. interaction_prior prior distribution interaction effects. Currently, two prior densities implemented: Unit Information prior (interaction_prior = \"UnitInfo\") Cauchy prior (interaction_prior = \"Cauchy\"). Defaults \"Cauchy\". cauchy_scale scale Cauchy prior interactions. Defaults 2.5. threshold_alpha, threshold_beta shape parameters Beta-prime prior thresholds. Default 1. convergence_criterion convergence criterion pseudoposterior values EM algorithm. Defaults sqrt(.Machine$double.eps). maximum_iterations maximum number EM iterations used. Defaults 1e3. warning issued procedure converged maximum_iterations iterations. thresholds matrix p rows max(m) columns, containing category thresholds node. Used starting values Newton-Raphson procedure. Optional. interactions matrix p rows p columns, containing pairwise association estimates -diagonal elements. Used starting values Newton-Raphson procedure. Optional.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/mppe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimize Pseudoposterior for an Ordinal Markov Random Field Model — mppe","text":"list containing: interactions: matrix p rows p columns, containing maximum pseudoposterior estimates pairwise associations -diagonal elements. thresholds: matrix p rows max(m) columns, containing maximum pseudoposterior estimates category thresholds node. hessian: square matrix sum(m) + p(p-1)/2 rows columns, evaluated maximum pseudoposterior estimates. top-left square contains thresholds, bottom-right square associations (form (1,2), (1, 3), ..., (2, 1), ...). case interaction_prior = \"UnitInfo\", list also contains p p matrix unit_info, contains asymptotic variances used set unit information prior association effects bgms function.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/mrfSampler.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample states of the ordinal MRF — mrfSampler","title":"Sample states of the ordinal MRF — mrfSampler","text":"function samples states ordinal MRF using Gibbs sampler. Gibbs sampler initiated random values response options, proceeds simulating states node logistic model using node states predictor variables.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/mrfSampler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample states of the ordinal MRF — mrfSampler","text":"","code":"mrfSampler(   no_states,   no_nodes,   no_categories,   interactions,   thresholds,   iter = 1000 )"},{"path":"https://maartenMarsman.github.io/bgms/reference/mrfSampler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample states of the ordinal MRF — mrfSampler","text":"no_states number states ordinal MRF generated. no_nodes number nodes ordinal MRF. no_categories Either positive integer vector positive integers length no_nodes. number response categories top base category: no_categories = 1 generates binary states. interactions symmetric no_nodes no_nodes matrix pairwise interactions. -diagonal elements used. thresholds no_nodes max(no_categories) matrix category thresholds. elements row r indicate thresholds node r. no_categories vector, first no_categories[r] elements used row r. iter number iterations used Gibbs sampler. function provides last state Gibbs sampler output. default set 1e3.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/mrfSampler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample states of the ordinal MRF — mrfSampler","text":"no_states no_nodes matrix simulated states ordinal MRF.","code":""},{"path":"https://maartenMarsman.github.io/bgms/reference/mrfSampler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample states of the ordinal MRF — mrfSampler","text":"","code":"# Generate responses from a network of five binary and ordinal variables. no_nodes = 5 no_categories = sample(1:5, size = no_nodes, replace = TRUE)  Interactions = matrix(0, nrow = no_nodes, ncol = no_nodes) Interactions[2, 1] = Interactions[4, 1] = Interactions[3, 2] =   Interactions[5, 2] = Interactions[5, 4] = .25 Interactions = Interactions + t(Interactions) Thresholds = matrix(0, nrow = no_nodes, ncol = max(no_categories)) x = mrfSampler(no_states = 1e3,                no_nodes = no_nodes,                no_categories = no_categories,                interactions = Interactions,                thresholds = Thresholds)"}]
